//
//  AudioRecordingService.swift
//  ios_realtime_trans
//
//  éŸ³é »éŒ„è£½æœå‹™ï¼šä½¿ç”¨ AVAudioEngine æ•æ‰éº¥å…‹é¢¨éŸ³é »ä¸¦è½‰æ›ç‚º WebM æ ¼å¼
//

import Foundation
import AVFoundation
import AudioToolbox
import Combine

/// éŸ³é »éŒ„è£½ç‹€æ…‹
enum AudioRecordingState: Equatable {
    case idle
    case recording
    case error(String)
}

/// éŸ³é »éŒ„è£½æœå‹™å”å®š
protocol AudioRecordingServiceProtocol {
    var recordingState: AudioRecordingState { get }
    var audioDataPublisher: AnyPublisher<Data, Never> { get }

    func requestPermission() async -> Bool
    func startRecording() throws
    func stopRecording()
}

/// éŸ³é »éŒ„è£½æœå‹™å¯¦ä½œ
@Observable
final class AudioRecordingService: AudioRecordingServiceProtocol {

    // MARK: - Properties

    private(set) var recordingState: AudioRecordingState = .idle

    private let audioEngine = AVAudioEngine()
    private var audioConverter: AVAudioConverter?
    private var inputFormat: AVAudioFormat?
    private var outputFormat: AVAudioFormat?

    // éŸ³é »ç·©è¡å€æ”¶é›†
    private var audioBufferCollector: [Data] = []
    private var bufferTimer: Timer?
    private let bufferInterval: TimeInterval = 0.25  // æ¯ 250ms ç™¼é€ä¸€æ¬¡

    // Combine Publishers
    private let audioDataSubject = PassthroughSubject<Data, Never>()

    var audioDataPublisher: AnyPublisher<Data, Never> {
        audioDataSubject.eraseToAnyPublisher()
    }

    // MARK: - Public Methods

    /// è«‹æ±‚éº¥å…‹é¢¨æ¬Šé™
    func requestPermission() async -> Bool {
        await withCheckedContinuation { continuation in
            AVAudioApplication.requestRecordPermission { granted in
                continuation.resume(returning: granted)
            }
        }
    }

    /// é–‹å§‹éŒ„éŸ³
    func startRecording() throws {
        guard recordingState != .recording else { return }

        // è¨­å®šéŸ³é » Session
        try configureAudioSession()

        // è¨­å®šéŸ³é »æ ¼å¼
        let inputNode = audioEngine.inputNode
        inputFormat = inputNode.outputFormat(forBus: 0)

        guard let inputFormat else {
            throw AudioRecordingError.invalidFormat
        }

        // ç›®æ¨™æ ¼å¼: 16kHz, mono, 16-bit PCM little-endian (èˆ‡ Google Speech LINEAR16 åŒ¹é…)
        // ä½¿ç”¨ AudioStreamBasicDescription ç¢ºä¿æ ¼å¼æ­£ç¢º
        var asbd = AudioStreamBasicDescription(
            mSampleRate: 16000,
            mFormatID: kAudioFormatLinearPCM,
            mFormatFlags: kLinearPCMFormatFlagIsSignedInteger | kLinearPCMFormatFlagIsPacked,
            mBytesPerPacket: 2,
            mFramesPerPacket: 1,
            mBytesPerFrame: 2,
            mChannelsPerFrame: 1,
            mBitsPerChannel: 16,
            mReserved: 0
        )
        outputFormat = AVAudioFormat(streamDescription: &asbd)

        guard let outputFormat else {
            throw AudioRecordingError.invalidFormat
        }

        // å»ºç«‹è½‰æ›å™¨
        audioConverter = AVAudioConverter(from: inputFormat, to: outputFormat)

        guard audioConverter != nil else {
            print("âŒ ç„¡æ³•å»ºç«‹éŸ³é »è½‰æ›å™¨")
            print("   è¼¸å…¥æ ¼å¼: sampleRate=\(inputFormat.sampleRate), channels=\(inputFormat.channelCount), format=\(inputFormat.commonFormat.rawValue)")
            print("   è¼¸å‡ºæ ¼å¼: sampleRate=\(outputFormat.sampleRate), channels=\(outputFormat.channelCount), format=\(outputFormat.commonFormat.rawValue)")
            throw AudioRecordingError.invalidFormat
        }

        // å®‰è£ Tap ä¾†æ•æ‰éŸ³é »
        let bufferSize: AVAudioFrameCount = 4096
        print("ğŸ¤ å®‰è£éŸ³é » Tap")
        print("   è¼¸å…¥æ ¼å¼: sampleRate=\(inputFormat.sampleRate), channels=\(inputFormat.channelCount), format=\(inputFormat.commonFormat.rawValue)")
        print("   è¼¸å‡ºæ ¼å¼: sampleRate=\(outputFormat.sampleRate), channels=\(outputFormat.channelCount)")

        inputNode.installTap(onBus: 0, bufferSize: bufferSize, format: inputFormat) { [weak self] buffer, _ in
            self?.processAudioBuffer(buffer)
        }

        // å•Ÿå‹•éŸ³é »å¼•æ“
        try audioEngine.start()
        print("ğŸ”Š éŸ³é »å¼•æ“å·²å•Ÿå‹•")

        // å•Ÿå‹•å®šæ™‚ç™¼é€å™¨
        startBufferTimer()

        recordingState = .recording
        print("ğŸ™ï¸ é–‹å§‹éŒ„éŸ³")
    }

    /// åœæ­¢éŒ„éŸ³
    func stopRecording() {
        guard recordingState == .recording else { return }

        // åœæ­¢å®šæ™‚å™¨
        stopBufferTimer()

        // ç™¼é€å‰©é¤˜ç·©è¡å€
        flushBuffer()

        // åœæ­¢éŸ³é »å¼•æ“
        audioEngine.inputNode.removeTap(onBus: 0)
        audioEngine.stop()

        // é‡è¨­éŸ³é » Session
        try? resetAudioSession()

        print("â¹ï¸ åœæ­¢éŒ„éŸ³ (ç¸½è¨ˆç™¼é€ \(sendCount) æ¬¡)")
        sendCount = 0
        recordingState = .idle
    }

    // MARK: - Private Methods

    /// è¨­å®šéŸ³é » Session
    private func configureAudioSession() throws {
        let session = AVAudioSession.sharedInstance()

        // â­ï¸ ä½¿ç”¨ .voiceChat mode å•Ÿç”¨å›éŸ³æ¶ˆé™¤
        // - Echo Cancellation: æ¶ˆé™¤æšè²å™¨æ’­æ”¾çš„è²éŸ³è¢«éº¥å…‹é¢¨æ”¶éŸ³
        // - Noise Suppression: æŠ‘åˆ¶èƒŒæ™¯å™ªéŸ³
        // - Automatic Gain Control: è‡ªå‹•èª¿æ•´éº¥å…‹é¢¨å¢ç›Š
        // ğŸ“± ç§»é™¤ .defaultToSpeakerï¼Œæ”¹ç”¨è½ç­’ï¼ˆearpieceï¼‰è¼¸å‡º
        try session.setCategory(.playAndRecord, mode: .voiceChat, options: [.allowBluetooth])
        try session.setActive(true)

        print("ğŸ”‡ [Audio Session] Echo Cancellation enabled (mode: .voiceChat)")
        print("ğŸ“± [Audio Session] Output route: Receiver (earpiece)")
    }

    /// é‡è¨­éŸ³é » Session
    private func resetAudioSession() throws {
        let session = AVAudioSession.sharedInstance()
        try session.setActive(false, options: .notifyOthersOnDeactivation)
    }

    /// è™•ç†éŸ³é »ç·©è¡å€
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let converter = audioConverter,
              let outputFormat else { return }

        // è¨ˆç®—è¼¸å‡ºç·©è¡å€å¤§å°
        let ratio = outputFormat.sampleRate / buffer.format.sampleRate
        let outputFrameCapacity = AVAudioFrameCount(Double(buffer.frameLength) * ratio) + 1

        guard let outputBuffer = AVAudioPCMBuffer(
            pcmFormat: outputFormat,
            frameCapacity: outputFrameCapacity
        ) else { return }

        // ä½¿ç”¨ inputBlock è¿½è¹¤æ˜¯å¦å·²ç¶“æä¾›éæ•¸æ“š
        var hasProvidedData = false

        // è½‰æ›éŸ³é »æ ¼å¼
        var error: NSError?
        let status = converter.convert(to: outputBuffer, error: &error) { _, outStatus in
            if hasProvidedData {
                // å·²ç¶“æä¾›éæ•¸æ“šï¼Œå‘ŠçŸ¥æ²’æœ‰æ›´å¤šæ•¸æ“š
                outStatus.pointee = .noDataNow
                return nil
            }
            hasProvidedData = true
            outStatus.pointee = .haveData
            return buffer
        }

        if status == .error || error != nil {
            print("âŒ éŸ³é »è½‰æ›éŒ¯èª¤: status=\(status.rawValue), error=\(error?.localizedDescription ?? "nil")")
            return
        }

        // å°‡è½‰æ›å¾Œçš„éŸ³é »æ•¸æ“šæ·»åŠ åˆ°ç·©è¡å€
        if let channelData = outputBuffer.int16ChannelData {
            let frameLength = Int(outputBuffer.frameLength)
            if frameLength > 0 {
                let data = Data(bytes: channelData[0], count: frameLength * 2)
                audioBufferCollector.append(data)

                // Debug: æª¢æŸ¥éŸ³é »æ•¸æ“šæ˜¯å¦æœ‰æ•ˆï¼ˆä¸å…¨æ˜¯éœéŸ³ï¼‰
                let samples = UnsafeBufferPointer(start: channelData[0], count: frameLength)
                let maxSample = samples.max() ?? 0
                let minSample = samples.min() ?? 0
                if abs(maxSample) > 100 || abs(minSample) > 100 {
                    // æœ‰éŸ³é »ä¿¡è™Ÿ
                } else if audioBufferCollector.count == 1 {
                    print("âš ï¸ éŸ³é »ä¼¼ä¹æ˜¯éœéŸ³ (max=\(maxSample), min=\(minSample))")
                }
            }
        } else {
            print("âš ï¸ outputBuffer.int16ChannelData ç‚º nil")
        }
    }

    /// å•Ÿå‹•ç·©è¡å€å®šæ™‚å™¨
    private func startBufferTimer() {
        bufferTimer = Timer.scheduledTimer(withTimeInterval: bufferInterval, repeats: true) { [weak self] _ in
            self?.flushBuffer()
        }
    }

    /// åœæ­¢ç·©è¡å€å®šæ™‚å™¨
    private func stopBufferTimer() {
        bufferTimer?.invalidate()
        bufferTimer = nil
    }

    /// ç™¼é€è¨ˆæ•¸å™¨
    private var sendCount = 0

    /// Google Speech API æœ€å¤§ chunk å¤§å°
    private let maxChunkSize = 25600

    /// æ¸…ç©ºä¸¦ç™¼é€ç·©è¡å€
    private func flushBuffer() {
        guard !audioBufferCollector.isEmpty else { return }

        // åˆä½µæ‰€æœ‰ç·©è¡å€
        var combinedData = Data()
        for buffer in audioBufferCollector {
            combinedData.append(buffer)
        }
        audioBufferCollector.removeAll()

        // åˆ†å‰²æˆæœ€å¤§ 25600 bytes çš„ chunks
        var offset = 0
        while offset < combinedData.count {
            let chunkSize = min(maxChunkSize, combinedData.count - offset)
            let chunk = combinedData.subdata(in: offset..<(offset + chunkSize))

            sendCount += 1
            // åªåœ¨ç¬¬ 1 æ¬¡å’Œæ¯ 20 æ¬¡è¼¸å‡º log
            if sendCount == 1 || sendCount % 20 == 0 {
                print("ğŸ“¤ ç™¼é€éŸ³é » #\(sendCount): \(chunk.count) bytes")
            }
            audioDataSubject.send(chunk)

            offset += chunkSize
        }
    }

    /// å»ºç«‹ WebM æ ¼å¼éŸ³é »æ•¸æ“š
    /// æ³¨æ„ï¼šé€™æ˜¯ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš› WebM éœ€è¦å®Œæ•´çš„å®¹å™¨æ ¼å¼
    /// ä½† Chirp3 çš„ autoDecodingConfig å¯ä»¥è™•ç† raw PCM
    private func createWebMAudioData(from pcmData: Data) -> Data {
        // é€™è£¡æˆ‘å€‘ç›´æ¥ç™¼é€ PCM æ•¸æ“šï¼Œå› ç‚º server çš„ autoDecodingConfig
        // æœƒè‡ªå‹•æª¢æ¸¬éŸ³é »æ ¼å¼
        return pcmData
    }
}

// MARK: - Errors

enum AudioRecordingError: LocalizedError {
    case permissionDenied
    case invalidFormat
    case engineStartFailed

    var errorDescription: String? {
        switch self {
        case .permissionDenied:
            return "éº¥å…‹é¢¨æ¬Šé™è¢«æ‹’çµ•"
        case .invalidFormat:
            return "ç„¡æ•ˆçš„éŸ³é »æ ¼å¼"
        case .engineStartFailed:
            return "ç„¡æ³•å•Ÿå‹•éŸ³é »å¼•æ“"
        }
    }
}
