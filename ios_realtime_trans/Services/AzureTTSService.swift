//
//  AzureTTSService.swift
//  ios_realtime_trans
//
//  Azure Text-to-Speech æœå‹™ï¼ˆWebSocket ä¸²æµç‰ˆï¼‰
//  é€é Cloud Run ä¸²æµ TTSï¼Œå³æ™‚æ¥æ”¶éŸ³è¨Šç‰‡æ®µ
//

import Foundation
import AVFoundation

/// Azure TTS ä¸²æµæœå‹™
class AzureTTSService {

    // WebSocket TTS ä¸²æµ URL
    private let streamURL = "wss://chirp3-ios-api-1027448899164.asia-east1.run.app/tts-stream"

    // WebSocket é€£æ¥
    private var webSocketTask: URLSessionWebSocketTask?
    private var urlSession: URLSession?

    // éŸ³è¨Šç‰‡æ®µç´¯ç©
    private var audioChunks: [Data] = []
    private var isReceiving = false

    // éŸ³é »æ’­æ”¾å™¨ï¼ˆä½¿ç”¨ AVAudioEngine ä¾†æ”¯æŒéŸ³é‡æ”¾å¤§ï¼‰
    private var audioEngine: AVAudioEngine?
    private var playerNode: AVAudioPlayerNode?
    private var eqNode: AVAudioUnitEQ?
    private var audioFile: AVAudioFile?

    // â­ï¸ éŸ³é‡å¢ç›Šï¼ˆdBï¼‰
    // 0 dB = æ­£å¸¸éŸ³é‡
    // +6 dB â‰ˆ 2 å€éŸ³é‡
    // +12 dB â‰ˆ 4 å€éŸ³é‡
    // +18 dB â‰ˆ 8 å€éŸ³é‡
    // +24 dB â‰ˆ 16 å€éŸ³é‡ï¼ˆé»˜èª - éå¸¸å¤§è²ï¼‰
    // å»ºè­°ç¯„åœï¼š0 ~ 40 dB
    var volumeBoostDB: Float = 24.0

    // å›èª¿
    private var onComplete: ((Result<Data, Error>) -> Void)?

    // å¤šèªè¨€èªéŸ³ï¼ˆæ”¯æ´ 41+ èªè¨€çš„è‡ªå‹•æª¢æ¸¬ï¼‰
    private let multilingualVoices: [String: String] = [
        "male": "en-US-RyanMultilingualNeural",
        "female": "en-US-JennyMultilingualNeural"
    ]

    // èªè¨€ç‰¹å®šèªéŸ³æ˜ å°„
    private let voiceMapping: [String: [String: String]] = [
        "zh": ["male": "zh-TW-YunJheNeural", "female": "zh-TW-HsiaoChenNeural"],
        "en": ["male": "en-US-GuyNeural", "female": "en-US-JennyNeural"],
        "ja": ["male": "ja-JP-KeitaNeural", "female": "ja-JP-NanamiNeural"],
        "ko": ["male": "ko-KR-InJoonNeural", "female": "ko-KR-SunHiNeural"],
        "es": ["male": "es-ES-AlvaroNeural", "female": "es-ES-ElviraNeural"],
        "fr": ["male": "fr-FR-HenriNeural", "female": "fr-FR-DeniseNeural"],
        "de": ["male": "de-DE-ConradNeural", "female": "de-DE-KatjaNeural"],
        "it": ["male": "it-IT-DiegoNeural", "female": "it-IT-ElsaNeural"],
        "pt": ["male": "pt-BR-AntonioNeural", "female": "pt-BR-FranciscaNeural"],
        "ru": ["male": "ru-RU-DmitryNeural", "female": "ru-RU-SvetlanaNeural"],
        "th": ["male": "th-TH-NiwatNeural", "female": "th-TH-PremwadeeNeural"],
        "vi": ["male": "vi-VN-NamMinhNeural", "female": "vi-VN-HoaiMyNeural"]
    ]

    /// é¸æ“‡åˆé©çš„èªéŸ³
    private func selectVoice(languageCode: String, gender: String = "female", useMultilingual: Bool = true) -> String {
        // å„ªå…ˆä½¿ç”¨å¤šèªè¨€è‡ªå‹•æª¢æ¸¬èªéŸ³
        if useMultilingual {
            return multilingualVoices[gender] ?? multilingualVoices["female"]!
        }

        // æå–èªè¨€ä»£ç¢¼ï¼ˆzh-TW â†’ zhï¼‰
        let baseLang = languageCode.split(separator: "-").first.map(String.init) ?? languageCode

        // å›é€€åˆ°ç‰¹å®šèªè¨€èªéŸ³
        if let voices = voiceMapping[baseLang] {
            return voices[gender] ?? voices["female"]!
        }

        // é è¨­ä½¿ç”¨ä¸­æ–‡å°ç£
        return voiceMapping["zh"]![gender]!
    }


    /// é€£æ¥ WebSocket
    private func connectWebSocket() {
        guard let url = URL(string: streamURL) else {
            print("âŒ [TTS Stream] Invalid URL")
            return
        }

        let configuration = URLSessionConfiguration.default
        urlSession = URLSession(configuration: configuration)
        webSocketTask = urlSession?.webSocketTask(with: url)
        webSocketTask?.resume()

        print("ğŸ”Œ [TTS Stream] WebSocket connected")

        // é–‹å§‹æ¥æ”¶è¨Šæ¯
        receiveMessage()
    }

    /// æ¥æ”¶ WebSocket è¨Šæ¯
    private func receiveMessage() {
        webSocketTask?.receive { [weak self] result in
            guard let self = self else { return }

            switch result {
            case .success(let message):
                switch message {
                case .string(let text):
                    self.handleMessage(text)
                case .data(let data):
                    if let text = String(data: data, encoding: .utf8) {
                        self.handleMessage(text)
                    }
                @unknown default:
                    break
                }

                // ç¹¼çºŒæ¥æ”¶ä¸‹ä¸€æ¢è¨Šæ¯
                if self.isReceiving {
                    self.receiveMessage()
                }

            case .failure(let error):
                print("âŒ [TTS Stream] WebSocket receive error: \(error)")
                self.onComplete?(.failure(error))
            }
        }
    }

    /// è™•ç†æ”¶åˆ°çš„è¨Šæ¯
    private func handleMessage(_ text: String) {
        guard let data = text.data(using: .utf8),
              let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
              let type = json["type"] as? String else {
            return
        }

        switch type {
        case "audio_chunk":
            if let base64Data = json["data"] as? String,
               let audioData = Data(base64Encoded: base64Data) {
                audioChunks.append(audioData)
                print("ğŸ“¦ [TTS Stream] Received chunk #\(audioChunks.count): \(audioData.count) bytes")
            }

        case "complete":
            isReceiving = false
            let totalChunks = json["totalChunks"] as? Int ?? 0
            let totalLatency = json["totalLatency"] as? Int ?? 0
            let firstByteLatency = json["firstByteLatency"] as? Int ?? 0

            print("âœ… [TTS Stream] Complete: \(totalChunks) chunks, \(totalLatency)ms total, \(firstByteLatency)ms first byte")

            // åˆä½µæ‰€æœ‰éŸ³è¨Šç‰‡æ®µ
            let completeAudio = audioChunks.reduce(Data(), +)
            print("ğŸµ [TTS Stream] Total audio: \(completeAudio.count) bytes")

            // å›èª¿æˆåŠŸ
            onComplete?(.success(completeAudio))

            // æ¸…ç†
            disconnectWebSocket()

        case "error":
            isReceiving = false
            let message = json["message"] as? String ?? "Unknown error"
            print("âŒ [TTS Stream] Error: \(message)")

            onComplete?(.failure(TTSError.serverError(message)))
            disconnectWebSocket()

        default:
            break
        }
    }

    /// æ–·é–‹ WebSocket
    private func disconnectWebSocket() {
        webSocketTask?.cancel(with: .goingAway, reason: nil)
        webSocketTask = nil
        urlSession?.invalidateAndCancel()
        urlSession = nil
        audioChunks.removeAll()
        onComplete = nil
    }

    /// ä½¿ç”¨ Azure TTS åˆæˆèªéŸ³ï¼ˆWebSocket ä¸²æµç‰ˆï¼‰
    /// - Parameters:
    ///   - text: è¦åˆæˆçš„æ–‡å­—
    ///   - languageCode: èªè¨€ä»£ç¢¼
    ///   - gender: æ€§åˆ¥åå¥½ ("male" æˆ– "female")
    ///   - useMultilingual: æ˜¯å¦ä½¿ç”¨å¤šèªè¨€è‡ªå‹•æª¢æ¸¬
    /// - Returns: éŸ³é »æ•¸æ“š
    func synthesize(text: String, languageCode: String = "zh-TW", gender: String = "female", useMultilingual: Bool = true) async throws -> Data {
        guard !text.isEmpty else {
            throw TTSError.emptyText
        }

        let voice = selectVoice(languageCode: languageCode, gender: gender, useMultilingual: useMultilingual)

        print("ğŸ™ï¸ [TTS Stream] Synthesizing with voice: \(voice)")
        print("   Text: \(text.prefix(50))\(text.count > 50 ? "..." : "")")

        // é‡ç½®ç‹€æ…‹
        audioChunks.removeAll()
        isReceiving = true

        // é€£æ¥ WebSocket
        connectWebSocket()

        // ç­‰å¾…é€£æ¥å»ºç«‹ï¼ˆç°¡å–®å»¶é²ï¼‰
        try? await Task.sleep(nanoseconds: 500_000_000) // 0.5s

        // ç™¼é€åˆæˆè«‹æ±‚
        let request: [String: Any] = [
            "type": "synthesize",
            "text": text,
            "languageCode": languageCode,
            "voice": voice,
            "gender": gender
        ]

        guard let jsonData = try? JSONSerialization.data(withJSONObject: request),
              let jsonString = String(data: jsonData, encoding: .utf8) else {
            throw TTSError.invalidRequest
        }

        let message = URLSessionWebSocketTask.Message.string(jsonString)
        webSocketTask?.send(message) { error in
            if let error = error {
                print("âŒ [TTS Stream] Send error: \(error)")
            } else {
                print("ğŸ“¤ [TTS Stream] Request sent")
            }
        }

        // ç­‰å¾…åˆæˆå®Œæˆ
        return try await withCheckedThrowingContinuation { continuation in
            onComplete = { result in
                continuation.resume(with: result)
            }
        }
    }

    /// ç›´æ¥æ”¾å¤§ PCM buffer çš„éŸ³é‡ï¼ˆä¿®æ”¹æ¨£æœ¬å€¼ï¼‰
    /// - Parameters:
    ///   - buffer: è¦æ”¾å¤§çš„éŸ³é » buffer
    ///   - gain: å¢ç›Šå€æ•¸
    private func amplifyBuffer(_ buffer: AVAudioPCMBuffer, gain: Float) -> AVAudioPCMBuffer? {
        let channelCount = Int(buffer.format.channelCount)
        let frameLength = Int(buffer.frameLength)
        let format = buffer.format

        print("ğŸ“Š [Buffer Format] Channels: \(channelCount), Frames: \(frameLength)")
        print("ğŸ“Š [Buffer Format] Sample rate: \(format.sampleRate)Hz, IsFloat: \(format.commonFormat == .pcmFormatFloat32)")
        print("ğŸ“Š [Buffer Format] CommonFormat: \(format.commonFormat.rawValue)")

        // æª¢æŸ¥åŸå§‹æ¨£æœ¬å€¼ï¼ˆå‰ 10 å€‹ï¼‰
        if let floatData = buffer.floatChannelData {
            let samples = floatData[0]
            var maxSample: Float = 0
            for i in 0..<min(10, Int(frameLength)) {
                maxSample = max(maxSample, abs(samples[i]))
                if i < 3 {
                    print("ğŸ“Š [Original Sample \(i)] \(samples[i])")
                }
            }
            print("ğŸ“Š [Original Max] \(maxSample)")
        } else if let int16Data = buffer.int16ChannelData {
            let samples = int16Data[0]
            var maxSample: Int16 = 0
            for i in 0..<min(10, Int(frameLength)) {
                maxSample = max(maxSample, abs(samples[i]))
                if i < 3 {
                    print("ğŸ“Š [Original Sample \(i)] \(samples[i])")
                }
            }
            print("ğŸ“Š [Original Max] \(maxSample)")
        } else {
            print("âŒ [Buffer Amplify] FAILED - No accessible channel data!")
            return nil
        }

        // å˜—è©¦ Float æ ¼å¼æ”¾å¤§
        if let floatChannelData = buffer.floatChannelData {
            print("âœ… [Buffer Amplify] Using FLOAT format")

            for channel in 0..<channelCount {
                let samples = floatChannelData[channel]
                for frame in 0..<frameLength {
                    let original = samples[frame]
                    let amplified = original * gain
                    // ç¡¬é™åˆ¶é˜²æ­¢å‰Šæ³¢
                    samples[frame] = min(max(amplified, -1.0), 1.0)
                }
            }

            // æª¢æŸ¥æ”¾å¤§å¾Œçš„æ¨£æœ¬å€¼
            let samples = floatChannelData[0]
            var maxAmplified: Float = 0
            for i in 0..<min(10, Int(frameLength)) {
                maxAmplified = max(maxAmplified, abs(samples[i]))
                if i < 3 {
                    print("ğŸ“Š [Amplified Sample \(i)] \(samples[i])")
                }
            }
            print("ğŸ“Š [Amplified Max] \(maxAmplified)")
            print("ğŸ”Š [Buffer Amplify] Successfully amplified \(frameLength) frames Ã— \(channelCount) channels with gain \(gain)x")

            return buffer
        }

        // å˜—è©¦ Int16 æ ¼å¼æ”¾å¤§ï¼ˆéœ€è¦è½‰æ›ï¼‰
        if let int16ChannelData = buffer.int16ChannelData {
            print("âš ï¸ [Buffer Amplify] Using INT16 format - need conversion")

            // å‰µå»º Float æ ¼å¼çš„ buffer
            let floatFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32,
                                           sampleRate: format.sampleRate,
                                           channels: format.channelCount,
                                           interleaved: false)!

            guard let floatBuffer = AVAudioPCMBuffer(pcmFormat: floatFormat, frameCapacity: buffer.frameCapacity) else {
                print("âŒ [Buffer Amplify] Failed to create float buffer")
                return nil
            }

            floatBuffer.frameLength = buffer.frameLength

            // è½‰æ› Int16 â†’ Float ä¸¦æ”¾å¤§
            guard let floatData = floatBuffer.floatChannelData else {
                print("âŒ [Buffer Amplify] No float channel data in new buffer")
                return nil
            }

            for channel in 0..<channelCount {
                let int16Samples = int16ChannelData[channel]
                let floatSamples = floatData[channel]

                for frame in 0..<frameLength {
                    // Int16 â†’ Float: é™¤ä»¥ 32768.0
                    let floatValue = Float(int16Samples[frame]) / 32768.0
                    // æ”¾å¤§ä¸¦é™åˆ¶
                    floatSamples[frame] = min(max(floatValue * gain, -1.0), 1.0)
                }
            }

            // æª¢æŸ¥æ”¾å¤§å¾Œçš„æ¨£æœ¬å€¼
            let samples = floatData[0]
            var maxAmplified: Float = 0
            for i in 0..<min(10, Int(frameLength)) {
                maxAmplified = max(maxAmplified, abs(samples[i]))
                if i < 3 {
                    print("ğŸ“Š [Amplified Sample \(i)] \(samples[i])")
                }
            }
            print("ğŸ“Š [Amplified Max] \(maxAmplified)")
            print("ğŸ”Š [Buffer Amplify] Converted and amplified \(frameLength) frames Ã— \(channelCount) channels with gain \(gain)x")

            return floatBuffer
        }

        print("âŒ [Buffer Amplify] Unsupported buffer format!")
        return nil
    }

    /// æ’­æ”¾åˆæˆçš„èªéŸ³ï¼ˆä½¿ç”¨ AVAudioUnitEQ æ”¯æŒéŸ³é‡æ”¾å¤§ï¼‰
    /// - Parameter audioData: éŸ³é »æ•¸æ“šï¼ˆMP3 æ ¼å¼ï¼‰
    func play(audioData: Data) throws {
        // åœæ­¢èˆŠçš„æ’­æ”¾
        stop()

        // 1. å°‡éŸ³é »æ•¸æ“šå¯«å…¥è‡¨æ™‚æ–‡ä»¶
        let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent(UUID().uuidString + ".mp3")
        try audioData.write(to: tempURL)

        // 2. å‰µå»º AVAudioFile
        audioFile = try AVAudioFile(forReading: tempURL)

        guard let audioFile = audioFile else {
            throw TTSError.serverError("Failed to create audio file")
        }

        print("ğŸ“¦ [Azure TTS] Audio file length: \(audioFile.length) frames")
        print("ğŸ“¦ [Azure TTS] Format: \(audioFile.processingFormat)")

        // 3. å‰µå»º AVAudioEngineã€PlayerNode å’Œ EQ
        audioEngine = AVAudioEngine()
        playerNode = AVAudioPlayerNode()

        // â­ï¸ é—œéµï¼šå‰µå»º AVAudioUnitEQ ç”¨æ–¼éŸ³é‡æ”¾å¤§
        eqNode = AVAudioUnitEQ(numberOfBands: 0)  // 0 bands = åªä½¿ç”¨ globalGain

        guard let audioEngine = audioEngine,
              let playerNode = playerNode,
              let eqNode = eqNode else {
            throw TTSError.serverError("Failed to create audio engine")
        }

        // 4. é€£æ¥ç¯€é»ï¼šPlayerNode â†’ EQ â†’ MainMixerNode â†’ Output
        audioEngine.attach(playerNode)
        audioEngine.attach(eqNode)

        let format = audioFile.processingFormat
        audioEngine.connect(playerNode, to: eqNode, format: format)
        audioEngine.connect(eqNode, to: audioEngine.mainMixerNode, format: format)

        // â­ï¸ è¨­ç½® EQ çš„ globalGainï¼ˆé€™å€‹æ–¹æ³•åœ¨éŒ„éŸ³æ™‚ä¹Ÿæœ‰æ•ˆï¼ï¼‰
        eqNode.globalGain = volumeBoostDB
        print("ğŸ”Š [Audio EQ] Global gain set to \(volumeBoostDB) dB")

        // 5. å•Ÿå‹•å¼•æ“
        try audioEngine.start()
        print("ğŸµ [Audio Engine] Started")

        // 6. ç›´æ¥æ’­æ”¾æ–‡ä»¶
        playerNode.scheduleFile(audioFile, at: nil) {
            print("âœ… [Azure TTS] Playback completed")
            DispatchQueue.main.async { [weak self] in
                self?.cleanupPlayback()
            }
        }
        playerNode.play()

        let duration = Double(audioFile.length) / audioFile.processingFormat.sampleRate
        print("â–¶ï¸ [Azure TTS] Playing audio (\(audioData.count) bytes, \(audioFile.length) frames, duration: \(String(format: "%.2f", duration))s, volume boost: +\(volumeBoostDB) dB)")
    }

    /// æ¸…ç†æ’­æ”¾è³‡æº
    private func cleanupPlayback() {
        print("ğŸ§¹ [Azure TTS] Cleaning up playback resources")

        if let node = playerNode, node.isPlaying {
            node.stop()
            print("   â¹ï¸ Stopped player node")
        }

        if let engine = audioEngine, engine.isRunning {
            engine.stop()
            print("   â¹ï¸ Stopped audio engine")
        }

        // åˆªé™¤è‡¨æ™‚æ–‡ä»¶
        if let audioFile = audioFile {
            try? FileManager.default.removeItem(at: audioFile.url)
            print("   ğŸ—‘ï¸ Removed temp file")
        }

        playerNode = nil
        eqNode = nil
        audioEngine = nil
        audioFile = nil

        print("âœ… [Azure TTS] Cleanup completed")
    }

    /// åœæ­¢æ’­æ”¾
    func stop() {
        print("â¹ï¸ [Azure TTS] Stop requested")
        cleanupPlayback()
    }

    /// æ˜¯å¦æ­£åœ¨æ’­æ”¾
    var isPlaying: Bool {
        playerNode?.isPlaying ?? false
    }
}

// MARK: - Errors

enum TTSError: LocalizedError {
    case emptyText
    case invalidURL
    case invalidResponse
    case invalidRequest
    case httpError(Int)
    case serverError(String)

    var errorDescription: String? {
        switch self {
        case .emptyText:
            return "æ–‡å­—ä¸èƒ½ç‚ºç©º"
        case .invalidURL:
            return "ç„¡æ•ˆçš„ URL"
        case .invalidResponse:
            return "ç„¡æ•ˆçš„å›æ‡‰"
        case .invalidRequest:
            return "ç„¡æ•ˆçš„è«‹æ±‚"
        case .httpError(let code):
            return "HTTP éŒ¯èª¤: \(code)"
        case .serverError(let message):
            return "ä¼ºæœå™¨éŒ¯èª¤: \(message)"
        }
    }
}
