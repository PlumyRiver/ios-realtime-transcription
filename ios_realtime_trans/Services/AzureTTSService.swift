//
//  AzureTTSService.swift
//  ios_realtime_trans
//
//  Azure Text-to-Speech æœå‹™ï¼ˆWebSocket ä¸²æµç‰ˆï¼‰
//  é€é Cloud Run ä¸²æµ TTSï¼Œå³æ™‚æ¥æ”¶éŸ³è¨Šç‰‡æ®µ
//

import Foundation
import AVFoundation

/// Azure TTS ä¸²æµæœå‹™
class AzureTTSService {

    // WebSocket TTS ä¸²æµ URL
    private let streamURL = "wss://chirp3-ios-api-1027448899164.asia-east1.run.app/tts-stream"

    // WebSocket é€£æ¥
    private var webSocketTask: URLSessionWebSocketTask?
    private var urlSession: URLSession?

    // éŸ³è¨Šç‰‡æ®µç´¯ç©
    private var audioChunks: [Data] = []
    private var isReceiving = false

    // éŸ³é »æ’­æ”¾å™¨ï¼ˆä½¿ç”¨ AVAudioEngine ä¾†æ”¯æŒéŸ³é‡æ”¾å¤§ï¼‰
    private var audioEngine: AVAudioEngine?
    private var playerNode: AVAudioPlayerNode?
    private var eqNode: AVAudioUnitEQ?
    private var audioFile: AVAudioFile?
    private var playbackTimer: Timer?

    // â­ï¸ éŸ³é‡å¢ç›Šï¼ˆdBï¼‰
    // é‡è¦ï¼šéé«˜çš„å¢ç›Šæœƒå°è‡´å‰Šæ³¢ï¼ˆç ´éŸ³ï¼‰ï¼Œä½† Voice Processing çš„ AGC æœƒå£“åˆ¶éŸ³é‡
    // çµæœï¼šç ´éŸ³ä½†æ²’è®Šå¤§è²
    // 0 dB = æ­£å¸¸éŸ³é‡
    // +6 dB â‰ˆ 2 å€éŸ³é‡ï¼ˆæ¨è–¦ - é…åˆæ“´éŸ³æ¨¡å¼å’Œç³»çµ±éŸ³é‡ï¼‰
    var volumeBoostDB: Float = 6.0

    // å›èª¿
    private var onComplete: ((Result<Data, Error>) -> Void)?

    // â­ï¸ èªè¨€ç‰¹å®šèªéŸ³æ˜ å°„ï¼ˆå®Œæ•´ 73 ç¨®èªè¨€ï¼‰
    // ä½¿ç”¨ Azure locale code ä½œç‚º keyï¼Œç¢ºä¿ç²¾ç¢ºåŒ¹é…
    private let voiceMapping: [String: [String: String]] = [
        // ===== ğŸ”¥ å°ç£äººæœ€å¸¸ç”¨ TOP 20 =====
        "zh-TW": ["male": "zh-TW-YunJheNeural", "female": "zh-TW-HsiaoChenNeural"],
        "en-US": ["male": "en-US-GuyNeural", "female": "en-US-JennyNeural"],
        "ja-JP": ["male": "ja-JP-KeitaNeural", "female": "ja-JP-NanamiNeural"],
        "ko-KR": ["male": "ko-KR-InJoonNeural", "female": "ko-KR-SunHiNeural"],
        "vi-VN": ["male": "vi-VN-NamMinhNeural", "female": "vi-VN-HoaiMyNeural"],
        "th-TH": ["male": "th-TH-NiwatNeural", "female": "th-TH-PremwadeeNeural"],
        "id-ID": ["male": "id-ID-ArdiNeural", "female": "id-ID-GadisNeural"],
        "fil-PH": ["male": "fil-PH-AngeloNeural", "female": "fil-PH-BlessicaNeural"],
        "ms-MY": ["male": "ms-MY-OsmanNeural", "female": "ms-MY-YasminNeural"],
        "my-MM": ["male": "my-MM-ThihaNeural", "female": "my-MM-NilarNeural"],
        "km-KH": ["male": "km-KH-PisethNeural", "female": "km-KH-SreymomNeural"],
        "es-ES": ["male": "es-ES-AlvaroNeural", "female": "es-ES-ElviraNeural"],
        "fr-FR": ["male": "fr-FR-HenriNeural", "female": "fr-FR-DeniseNeural"],
        "de-DE": ["male": "de-DE-ConradNeural", "female": "de-DE-KatjaNeural"],
        "pt-BR": ["male": "pt-BR-AntonioNeural", "female": "pt-BR-FranciscaNeural"],
        "it-IT": ["male": "it-IT-DiegoNeural", "female": "it-IT-ElsaNeural"],
        "ru-RU": ["male": "ru-RU-DmitryNeural", "female": "ru-RU-SvetlanaNeural"],
        "ar-SA": ["male": "ar-SA-HamedNeural", "female": "ar-SA-ZariyahNeural"],
        "tr-TR": ["male": "tr-TR-AhmetNeural", "female": "tr-TR-EmelNeural"],

        // ===== ğŸŒ æ±å—äº =====
        "lo-LA": ["male": "lo-LA-ChanthavongNeural", "female": "lo-LA-KeomanyNeural"],
        "jv-ID": ["male": "jv-ID-DimasNeural", "female": "jv-ID-SitiNeural"],
        "su-ID": ["male": "su-ID-JajangNeural", "female": "su-ID-TutiNeural"],

        // ===== ğŸŒ¸ æ±äº =====
        "zh-CN": ["male": "zh-CN-YunxiNeural", "female": "zh-CN-XiaoxiaoNeural"],
        "zh-HK": ["male": "zh-HK-WanLungNeural", "female": "zh-HK-HiuGaaiNeural"],

        // ===== ğŸ•Œ å—äº =====
        "hi-IN": ["male": "hi-IN-MadhurNeural", "female": "hi-IN-SwaraNeural"],
        "bn-IN": ["male": "bn-IN-BashkarNeural", "female": "bn-IN-TanishaaNeural"],
        "ta-IN": ["male": "ta-IN-ValluvarNeural", "female": "ta-IN-PallaviNeural"],
        "te-IN": ["male": "te-IN-MohanNeural", "female": "te-IN-ShrutiNeural"],
        "mr-IN": ["male": "mr-IN-ManoharNeural", "female": "mr-IN-AarohiNeural"],
        "gu-IN": ["male": "gu-IN-NiranjanNeural", "female": "gu-IN-DhwaniNeural"],
        "kn-IN": ["male": "kn-IN-GaganNeural", "female": "kn-IN-SapnaNeural"],
        "ml-IN": ["male": "ml-IN-MidhunNeural", "female": "ml-IN-SobhanaNeural"],
        "pa-IN": ["male": "pa-IN-GurpreetNeural", "female": "pa-IN-AmritaNeural"],  // âš ï¸ æ³¨æ„ï¼šAzure å¯èƒ½ç”¨ pa-IN
        "si-LK": ["male": "si-LK-SameeraNeural", "female": "si-LK-ThiliniNeural"],
        "ne-NP": ["male": "ne-NP-SagarNeural", "female": "ne-NP-HemkalaNeural"],
        "ur-PK": ["male": "ur-PK-AsadNeural", "female": "ur-PK-UzmaNeural"],

        // ===== ğŸ•Œ ä¸­æ± =====
        "fa-IR": ["male": "fa-IR-FaridNeural", "female": "fa-IR-DilaraNeural"],
        "he-IL": ["male": "he-IL-AvriNeural", "female": "he-IL-HilaNeural"],
        "ar-EG": ["male": "ar-EG-ShakirNeural", "female": "ar-EG-SalmaNeural"],

        // ===== ğŸ‡ªğŸ‡º æ­æ´² =====
        "nl-NL": ["male": "nl-NL-MaartenNeural", "female": "nl-NL-ColetteNeural"],
        "pl-PL": ["male": "pl-PL-MarekNeural", "female": "pl-PL-AgnieszkaNeural"],
        "uk-UA": ["male": "uk-UA-OstapNeural", "female": "uk-UA-PolinaNeural"],
        "cs-CZ": ["male": "cs-CZ-AntoninNeural", "female": "cs-CZ-VlastaNeural"],
        "ro-RO": ["male": "ro-RO-EmilNeural", "female": "ro-RO-AlinaNeural"],
        "hu-HU": ["male": "hu-HU-TamasNeural", "female": "hu-HU-NoemiNeural"],
        "el-GR": ["male": "el-GR-NestorasNeural", "female": "el-GR-AthinaNeural"],
        "sv-SE": ["male": "sv-SE-MattiasNeural", "female": "sv-SE-SofieNeural"],
        "da-DK": ["male": "da-DK-JeppeNeural", "female": "da-DK-ChristelNeural"],
        "fi-FI": ["male": "fi-FI-HarriNeural", "female": "fi-FI-NooraNeural"],
        "nb-NO": ["male": "nb-NO-FinnNeural", "female": "nb-NO-PernilleNeural"],
        "sk-SK": ["male": "sk-SK-LukasNeural", "female": "sk-SK-ViktoriaNeural"],
        "bg-BG": ["male": "bg-BG-BorislavNeural", "female": "bg-BG-KalinaNeural"],
        "hr-HR": ["male": "hr-HR-SreckoNeural", "female": "hr-HR-GabrijelaNeural"],
        "sl-SI": ["male": "sl-SI-RokNeural", "female": "sl-SI-PetraNeural"],
        "sr-RS": ["male": "sr-RS-NicholasNeural", "female": "sr-RS-SophieNeural"],
        "lt-LT": ["male": "lt-LT-LeonasNeural", "female": "lt-LT-OnaNeural"],
        "lv-LV": ["male": "lv-LV-NilsNeural", "female": "lv-LV-EveritaNeural"],
        "et-EE": ["male": "et-EE-KertNeural", "female": "et-EE-AnuNeural"],
        "is-IS": ["male": "is-IS-GunnarNeural", "female": "is-IS-GudrunNeural"],
        "mk-MK": ["male": "mk-MK-AleksandarNeural", "female": "mk-MK-MarijaNeural"],
        "mt-MT": ["male": "mt-MT-JosephNeural", "female": "mt-MT-GraceNeural"],
        "sq-AL": ["male": "sq-AL-IlirNeural", "female": "sq-AL-AnilaNeural"],
        "bs-BA": ["male": "bs-BA-GoranNeural", "female": "bs-BA-VesnaNeural"],
        "ca-ES": ["male": "ca-ES-EnricNeural", "female": "ca-ES-JoanaNeural"],
        "gl-ES": ["male": "gl-ES-RoiNeural", "female": "gl-ES-SabelaNeural"],
        "eu-ES": ["male": "eu-ES-AnderNeural", "female": "eu-ES-AinhoaNeural"],
        "cy-GB": ["male": "cy-GB-AledNeural", "female": "cy-GB-NiaNeural"],
        "ga-IE": ["male": "ga-IE-ColmNeural", "female": "ga-IE-OrlaNeural"],

        // ===== ğŸŒ éæ´² =====
        "af-ZA": ["male": "af-ZA-WillemNeural", "female": "af-ZA-AdriNeural"],
        "sw-KE": ["male": "sw-KE-RafikiNeural", "female": "sw-KE-ZuriNeural"],
        "am-ET": ["male": "am-ET-AmehaNeural", "female": "am-ET-MekdesNeural"],
        "zu-ZA": ["male": "zu-ZA-ThembaNeural", "female": "zu-ZA-ThandoNeural"],

        // ===== ğŸŒ å…¶ä»– =====
        "az-AZ": ["male": "az-AZ-BabekNeural", "female": "az-AZ-BanuNeural"],
        "kk-KZ": ["male": "kk-KZ-DauletNeural", "female": "kk-KZ-AigulNeural"],
        "uz-UZ": ["male": "uz-UZ-SardorNeural", "female": "uz-UZ-MadinaNeural"],
        "mn-MN": ["male": "mn-MN-BataaNeural", "female": "mn-MN-YesUINeural"],
        "ka-GE": ["male": "ka-GE-GiorgiNeural", "female": "ka-GE-EkaNeural"],
        "hy-AM": ["male": "hy-AM-HaykNeural", "female": "hy-AM-AnahitNeural"]
    ]

    /// é¸æ“‡åˆé©çš„èªéŸ³ï¼ˆæ ¹æ“šå®Œæ•´ locale codeï¼‰
    private func selectVoice(languageCode: String, gender: String = "female") -> String {
        // â­ï¸ ç›´æ¥ä½¿ç”¨å®Œæ•´ locale code æŸ¥æ‰¾å°ˆç”¨èªéŸ³
        if let voices = voiceMapping[languageCode] {
            return voices[gender] ?? voices["female"]!
        }

        // å˜—è©¦ä½¿ç”¨åŸºç¤èªè¨€ä»£ç¢¼ï¼ˆå¦‚ "vi" â†’ æ‰¾ "vi-VN"ï¼‰
        let baseLang = languageCode.split(separator: "-").first.map(String.init) ?? languageCode
        for (locale, voices) in voiceMapping {
            if locale.hasPrefix(baseLang + "-") {
                print("âš ï¸ [TTS] ä½¿ç”¨ \(locale) èªéŸ³æ›¿ä»£ \(languageCode)")
                return voices[gender] ?? voices["female"]!
            }
        }

        // é è¨­ä½¿ç”¨ä¸­æ–‡å°ç£
        print("âš ï¸ [TTS] æ‰¾ä¸åˆ° \(languageCode) èªéŸ³ï¼Œä½¿ç”¨é è¨­ zh-TW")
        return voiceMapping["zh-TW"]!["female"]!
    }


    /// é€£æ¥ WebSocket
    private func connectWebSocket() {
        guard let url = URL(string: streamURL) else {
            print("âŒ [TTS Stream] Invalid URL")
            return
        }

        let configuration = URLSessionConfiguration.default
        urlSession = URLSession(configuration: configuration)
        webSocketTask = urlSession?.webSocketTask(with: url)
        webSocketTask?.resume()

        print("ğŸ”Œ [TTS Stream] WebSocket connected")

        // é–‹å§‹æ¥æ”¶è¨Šæ¯
        receiveMessage()
    }

    /// æ¥æ”¶ WebSocket è¨Šæ¯
    private func receiveMessage() {
        webSocketTask?.receive { [weak self] result in
            guard let self = self else { return }

            switch result {
            case .success(let message):
                switch message {
                case .string(let text):
                    self.handleMessage(text)
                case .data(let data):
                    if let text = String(data: data, encoding: .utf8) {
                        self.handleMessage(text)
                    }
                @unknown default:
                    break
                }

                // ç¹¼çºŒæ¥æ”¶ä¸‹ä¸€æ¢è¨Šæ¯
                if self.isReceiving {
                    self.receiveMessage()
                }

            case .failure(let error):
                print("âŒ [TTS Stream] WebSocket receive error: \(error)")
                self.onComplete?(.failure(error))
            }
        }
    }

    /// è™•ç†æ”¶åˆ°çš„è¨Šæ¯
    private func handleMessage(_ text: String) {
        guard let data = text.data(using: .utf8),
              let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
              let type = json["type"] as? String else {
            return
        }

        switch type {
        case "audio_chunk":
            if let base64Data = json["data"] as? String,
               let audioData = Data(base64Encoded: base64Data) {
                audioChunks.append(audioData)
                print("ğŸ“¦ [TTS Stream] Received chunk #\(audioChunks.count): \(audioData.count) bytes")
            }

        case "complete":
            isReceiving = false
            let totalChunks = json["totalChunks"] as? Int ?? 0
            let totalLatency = json["totalLatency"] as? Int ?? 0
            let firstByteLatency = json["firstByteLatency"] as? Int ?? 0

            print("âœ… [TTS Stream] Complete: \(totalChunks) chunks, \(totalLatency)ms total, \(firstByteLatency)ms first byte")

            // åˆä½µæ‰€æœ‰éŸ³è¨Šç‰‡æ®µ
            let completeAudio = audioChunks.reduce(Data(), +)
            print("ğŸµ [TTS Stream] Total audio: \(completeAudio.count) bytes")

            // å›èª¿æˆåŠŸ
            onComplete?(.success(completeAudio))

            // æ¸…ç†
            disconnectWebSocket()

        case "error":
            isReceiving = false
            let message = json["message"] as? String ?? "Unknown error"
            print("âŒ [TTS Stream] Error: \(message)")

            onComplete?(.failure(TTSError.serverError(message)))
            disconnectWebSocket()

        default:
            break
        }
    }

    /// æ–·é–‹ WebSocket
    private func disconnectWebSocket() {
        webSocketTask?.cancel(with: .goingAway, reason: nil)
        webSocketTask = nil
        urlSession?.invalidateAndCancel()
        urlSession = nil
        audioChunks.removeAll()
        onComplete = nil
    }

    /// ä½¿ç”¨ Azure TTS åˆæˆèªéŸ³ï¼ˆWebSocket ä¸²æµç‰ˆï¼‰
    /// - Parameters:
    ///   - text: è¦åˆæˆçš„æ–‡å­—
    ///   - languageCode: èªè¨€ä»£ç¢¼ï¼ˆå®Œæ•´ Azure localeï¼Œå¦‚ "vi-VN", "zh-TW"ï¼‰
    ///   - gender: æ€§åˆ¥åå¥½ ("male" æˆ– "female")
    /// - Returns: éŸ³é »æ•¸æ“š
    func synthesize(text: String, languageCode: String = "zh-TW", gender: String = "female") async throws -> Data {
        guard !text.isEmpty else {
            throw TTSError.emptyText
        }

        // â­ï¸ ä½¿ç”¨èªè¨€å°ˆç”¨èªéŸ³ï¼ˆä¸å†ä½¿ç”¨å¤šèªè¨€èªéŸ³ï¼‰
        let voice = selectVoice(languageCode: languageCode, gender: gender)

        print("ğŸ™ï¸ [TTS Stream] Synthesizing with voice: \(voice)")
        print("   Text: \(text.prefix(50))\(text.count > 50 ? "..." : "")")

        // é‡ç½®ç‹€æ…‹
        audioChunks.removeAll()
        isReceiving = true

        // é€£æ¥ WebSocket
        connectWebSocket()

        // ç­‰å¾…é€£æ¥å»ºç«‹ï¼ˆç°¡å–®å»¶é²ï¼‰
        try? await Task.sleep(nanoseconds: 500_000_000) // 0.5s

        // ç™¼é€åˆæˆè«‹æ±‚
        let request: [String: Any] = [
            "type": "synthesize",
            "text": text,
            "languageCode": languageCode,
            "voice": voice,
            "gender": gender
        ]

        guard let jsonData = try? JSONSerialization.data(withJSONObject: request),
              let jsonString = String(data: jsonData, encoding: .utf8) else {
            throw TTSError.invalidRequest
        }

        let message = URLSessionWebSocketTask.Message.string(jsonString)
        webSocketTask?.send(message) { error in
            if let error = error {
                print("âŒ [TTS Stream] Send error: \(error)")
            } else {
                print("ğŸ“¤ [TTS Stream] Request sent")
            }
        }

        // ç­‰å¾…åˆæˆå®Œæˆ
        return try await withCheckedThrowingContinuation { continuation in
            onComplete = { result in
                continuation.resume(with: result)
            }
        }
    }

    /// ç›´æ¥æ”¾å¤§ PCM buffer çš„éŸ³é‡ï¼ˆä¿®æ”¹æ¨£æœ¬å€¼ï¼‰
    /// - Parameters:
    ///   - buffer: è¦æ”¾å¤§çš„éŸ³é » buffer
    ///   - gain: å¢ç›Šå€æ•¸
    private func amplifyBuffer(_ buffer: AVAudioPCMBuffer, gain: Float) -> AVAudioPCMBuffer? {
        let channelCount = Int(buffer.format.channelCount)
        let frameLength = Int(buffer.frameLength)
        let format = buffer.format

        print("ğŸ“Š [Buffer Format] Channels: \(channelCount), Frames: \(frameLength)")
        print("ğŸ“Š [Buffer Format] Sample rate: \(format.sampleRate)Hz, IsFloat: \(format.commonFormat == .pcmFormatFloat32)")
        print("ğŸ“Š [Buffer Format] CommonFormat: \(format.commonFormat.rawValue)")

        // æª¢æŸ¥åŸå§‹æ¨£æœ¬å€¼ï¼ˆå‰ 10 å€‹ï¼‰
        if let floatData = buffer.floatChannelData {
            let samples = floatData[0]
            var maxSample: Float = 0
            for i in 0..<min(10, Int(frameLength)) {
                maxSample = max(maxSample, abs(samples[i]))
                if i < 3 {
                    print("ğŸ“Š [Original Sample \(i)] \(samples[i])")
                }
            }
            print("ğŸ“Š [Original Max] \(maxSample)")
        } else if let int16Data = buffer.int16ChannelData {
            let samples = int16Data[0]
            var maxSample: Int16 = 0
            for i in 0..<min(10, Int(frameLength)) {
                maxSample = max(maxSample, abs(samples[i]))
                if i < 3 {
                    print("ğŸ“Š [Original Sample \(i)] \(samples[i])")
                }
            }
            print("ğŸ“Š [Original Max] \(maxSample)")
        } else {
            print("âŒ [Buffer Amplify] FAILED - No accessible channel data!")
            return nil
        }

        // å˜—è©¦ Float æ ¼å¼æ”¾å¤§
        if let floatChannelData = buffer.floatChannelData {
            print("âœ… [Buffer Amplify] Using FLOAT format")

            for channel in 0..<channelCount {
                let samples = floatChannelData[channel]
                for frame in 0..<frameLength {
                    let original = samples[frame]
                    let amplified = original * gain
                    // ç¡¬é™åˆ¶é˜²æ­¢å‰Šæ³¢
                    samples[frame] = min(max(amplified, -1.0), 1.0)
                }
            }

            // æª¢æŸ¥æ”¾å¤§å¾Œçš„æ¨£æœ¬å€¼
            let samples = floatChannelData[0]
            var maxAmplified: Float = 0
            for i in 0..<min(10, Int(frameLength)) {
                maxAmplified = max(maxAmplified, abs(samples[i]))
                if i < 3 {
                    print("ğŸ“Š [Amplified Sample \(i)] \(samples[i])")
                }
            }
            print("ğŸ“Š [Amplified Max] \(maxAmplified)")
            print("ğŸ”Š [Buffer Amplify] Successfully amplified \(frameLength) frames Ã— \(channelCount) channels with gain \(gain)x")

            return buffer
        }

        // å˜—è©¦ Int16 æ ¼å¼æ”¾å¤§ï¼ˆéœ€è¦è½‰æ›ï¼‰
        if let int16ChannelData = buffer.int16ChannelData {
            print("âš ï¸ [Buffer Amplify] Using INT16 format - need conversion")

            // å‰µå»º Float æ ¼å¼çš„ buffer
            let floatFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32,
                                           sampleRate: format.sampleRate,
                                           channels: format.channelCount,
                                           interleaved: false)!

            guard let floatBuffer = AVAudioPCMBuffer(pcmFormat: floatFormat, frameCapacity: buffer.frameCapacity) else {
                print("âŒ [Buffer Amplify] Failed to create float buffer")
                return nil
            }

            floatBuffer.frameLength = buffer.frameLength

            // è½‰æ› Int16 â†’ Float ä¸¦æ”¾å¤§
            guard let floatData = floatBuffer.floatChannelData else {
                print("âŒ [Buffer Amplify] No float channel data in new buffer")
                return nil
            }

            for channel in 0..<channelCount {
                let int16Samples = int16ChannelData[channel]
                let floatSamples = floatData[channel]

                for frame in 0..<frameLength {
                    // Int16 â†’ Float: é™¤ä»¥ 32768.0
                    let floatValue = Float(int16Samples[frame]) / 32768.0
                    // æ”¾å¤§ä¸¦é™åˆ¶
                    floatSamples[frame] = min(max(floatValue * gain, -1.0), 1.0)
                }
            }

            // æª¢æŸ¥æ”¾å¤§å¾Œçš„æ¨£æœ¬å€¼
            let samples = floatData[0]
            var maxAmplified: Float = 0
            for i in 0..<min(10, Int(frameLength)) {
                maxAmplified = max(maxAmplified, abs(samples[i]))
                if i < 3 {
                    print("ğŸ“Š [Amplified Sample \(i)] \(samples[i])")
                }
            }
            print("ğŸ“Š [Amplified Max] \(maxAmplified)")
            print("ğŸ”Š [Buffer Amplify] Converted and amplified \(frameLength) frames Ã— \(channelCount) channels with gain \(gain)x")

            return floatBuffer
        }

        print("âŒ [Buffer Amplify] Unsupported buffer format!")
        return nil
    }

    /// æ’­æ”¾åˆæˆçš„èªéŸ³ï¼ˆä½¿ç”¨ AVAudioUnitEQ æ”¯æŒéŸ³é‡æ”¾å¤§ï¼‰
    /// - Parameter audioData: éŸ³é »æ•¸æ“šï¼ˆMP3 æ ¼å¼ï¼‰
    func play(audioData: Data) throws {
        // åœæ­¢èˆŠçš„æ’­æ”¾
        stop()

        // â­ï¸ æª¢æŸ¥ Audio Session ç‹€æ…‹ï¼ˆç¢ºèªå›éŸ³æ¶ˆé™¤æ˜¯å¦å•Ÿç”¨ï¼‰
        let session = AVAudioSession.sharedInstance()
        print("ğŸ” [TTS] Audio Session Check:")
        print("   Category: \(session.category.rawValue)")
        print("   Mode: \(session.mode.rawValue) (æ‡‰è©²æ˜¯ AVAudioSessionModeVoiceChat)")
        print("   Route: \(session.currentRoute.outputs.first?.portType.rawValue ?? "unknown")")

        // 1. å°‡éŸ³é »æ•¸æ“šå¯«å…¥è‡¨æ™‚æ–‡ä»¶
        let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent(UUID().uuidString + ".mp3")
        try audioData.write(to: tempURL)

        // 2. å‰µå»º AVAudioFile
        audioFile = try AVAudioFile(forReading: tempURL)

        guard let audioFile = audioFile else {
            throw TTSError.serverError("Failed to create audio file")
        }

        print("ğŸ“¦ [Azure TTS] Audio file length: \(audioFile.length) frames")
        print("ğŸ“¦ [Azure TTS] Format: \(audioFile.processingFormat)")

        // 3. å‰µå»º AVAudioEngineã€PlayerNode å’Œ EQ
        audioEngine = AVAudioEngine()
        playerNode = AVAudioPlayerNode()

        // â­ï¸ é—œéµï¼šå‰µå»º AVAudioUnitEQ ç”¨æ–¼éŸ³é‡æ”¾å¤§ï¼ˆè‡³å°‘éœ€è¦ 1 å€‹ bandï¼‰
        eqNode = AVAudioUnitEQ(numberOfBands: 1)

        guard let audioEngine = audioEngine,
              let playerNode = playerNode,
              let eqNode = eqNode else {
            throw TTSError.serverError("Failed to create audio engine")
        }

        // 4. é€£æ¥ç¯€é»ï¼šPlayerNode â†’ EQ â†’ MainMixerNode â†’ Output
        audioEngine.attach(playerNode)
        audioEngine.attach(eqNode)

        let format = audioFile.processingFormat
        audioEngine.connect(playerNode, to: eqNode, format: format)
        audioEngine.connect(eqNode, to: audioEngine.mainMixerNode, format: format)

        // â­ï¸ è¨­ç½® EQ åƒæ•¸
        // globalGain æ”¾å¤§æ•´é«”éŸ³é‡
        eqNode.globalGain = volumeBoostDB

        // è¨­ç½®ç¬¬ä¸€å€‹ band ç‚º peak filter ä¸¦æ”¾å¤§
        let band = eqNode.bands[0]
        band.filterType = .parametric
        band.frequency = 1000  // ä¸­é »ï¼ˆäººè²ç¯„åœï¼‰
        band.bandwidth = 2.0
        band.gain = volumeBoostDB  // â­ï¸ ä½¿ç”¨å®Œæ•´å¢ç›Šï¼ˆç–ŠåŠ æ•ˆæœï¼‰
        band.bypass = false

        print("ğŸ”Š [Audio EQ] Global gain: \(volumeBoostDB) dB")
        print("ğŸ”Š [Audio EQ] Band 0 gain: \(band.gain) dB at \(band.frequency) Hz")
        print("ğŸ”Š [Audio EQ] Total boost: +\(volumeBoostDB + band.gain) dB (ç´„ \(Int(pow(10.0, (volumeBoostDB + band.gain) / 20.0))) å€)")

        // â­ï¸ åŒæ™‚è¨­ç½® PlayerNode éŸ³é‡åˆ°æœ€å¤§
        playerNode.volume = 1.0

        // â­ï¸ MainMixer ä¹Ÿè¨­ç½®åˆ°æœ€å¤§
        audioEngine.mainMixerNode.outputVolume = 1.0

        // 5. å•Ÿå‹•å¼•æ“
        do {
            try audioEngine.start()
            print("ğŸµ [Audio Engine] Started successfully")
        } catch {
            print("âŒ [Audio Engine] Failed to start: \(error)")
            throw error
        }

        // è®€å–ä¸¦é©—è­‰è¨­ç½®
        print("âœ… [Verification] EQ globalGain = \(eqNode.globalGain) dB")
        print("âœ… [Verification] PlayerNode volume = \(playerNode.volume)")
        print("âœ… [Verification] MainMixer volume = \(audioEngine.mainMixerNode.outputVolume)")
        print("âœ… [Verification] Engine running: \(audioEngine.isRunning)")

        // 6. ç›´æ¥æ’­æ”¾æ–‡ä»¶
        print("ğŸ“‹ [Scheduling] About to schedule file with \(audioFile.length) frames")
        playerNode.scheduleFile(audioFile, at: nil, completionCallbackType: .dataPlayedBack) { _ in
            print("âœ… [Callback] Schedule completion triggered")
        }

        print("â–¶ï¸ [Playing] Starting playback...")
        playerNode.play()

        let duration = Double(audioFile.length) / audioFile.processingFormat.sampleRate
        print("â–¶ï¸ [Azure TTS] Playing audio (\(audioData.count) bytes, \(audioFile.length) frames, duration: \(String(format: "%.2f", duration))s, total boost: +\(volumeBoostDB + band.gain) dB)")
        print("âœ… [Playing] PlayerNode.isPlaying = \(playerNode.isPlaying)")

        // â­ï¸ ä½¿ç”¨å®šæ™‚å™¨ç›£æ§æ’­æ”¾ç‹€æ…‹
        playbackTimer?.invalidate()
        playbackTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] timer in
            guard let self = self,
                  let node = self.playerNode else {
                timer.invalidate()
                return
            }

            // æª¢æŸ¥æ˜¯å¦é‚„åœ¨æ’­æ”¾
            if !node.isPlaying {
                print("âœ… [Timer] Playback finished, cleaning up...")
                timer.invalidate()
                DispatchQueue.main.async {
                    self.cleanupPlayback()
                }
            }
        }
        print("â±ï¸ [Timer] Started playback monitor")
    }

    /// æ¸…ç†æ’­æ”¾è³‡æº
    private func cleanupPlayback() {
        print("ğŸ§¹ [Azure TTS] Cleaning up playback resources")

        // åœæ­¢å®šæ™‚å™¨
        playbackTimer?.invalidate()
        playbackTimer = nil
        print("   â±ï¸ Stopped timer")

        if let node = playerNode, node.isPlaying {
            node.stop()
            print("   â¹ï¸ Stopped player node")
        }

        if let engine = audioEngine, engine.isRunning {
            engine.stop()
            print("   â¹ï¸ Stopped audio engine")
        }

        // åˆªé™¤è‡¨æ™‚æ–‡ä»¶
        if let audioFile = audioFile {
            try? FileManager.default.removeItem(at: audioFile.url)
            print("   ğŸ—‘ï¸ Removed temp file")
        }

        playerNode = nil
        eqNode = nil
        audioEngine = nil
        audioFile = nil

        print("âœ… [Azure TTS] Cleanup completed")
    }

    /// åœæ­¢æ’­æ”¾
    func stop() {
        print("â¹ï¸ [Azure TTS] Stop requested")
        cleanupPlayback()
    }

    /// æ˜¯å¦æ­£åœ¨æ’­æ”¾
    var isPlaying: Bool {
        playerNode?.isPlaying ?? false
    }
}

// MARK: - Errors

enum TTSError: LocalizedError {
    case emptyText
    case invalidURL
    case invalidResponse
    case invalidRequest
    case httpError(Int)
    case serverError(String)

    var errorDescription: String? {
        switch self {
        case .emptyText:
            return "æ–‡å­—ä¸èƒ½ç‚ºç©º"
        case .invalidURL:
            return "ç„¡æ•ˆçš„ URL"
        case .invalidResponse:
            return "ç„¡æ•ˆçš„å›æ‡‰"
        case .invalidRequest:
            return "ç„¡æ•ˆçš„è«‹æ±‚"
        case .httpError(let code):
            return "HTTP éŒ¯èª¤: \(code)"
        case .serverError(let message):
            return "ä¼ºæœå™¨éŒ¯èª¤: \(message)"
        }
    }
}
