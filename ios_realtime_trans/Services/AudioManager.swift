//
//  AudioManager.swift
//  ios_realtime_trans
//
//  çµ±ä¸€éŸ³é »ç®¡ç†å™¨ï¼šæ•´åˆéŒ„éŸ³å’Œ TTS æ’­æ”¾åˆ°åŒä¸€å€‹ AVAudioEngine
//  åˆ©ç”¨ iOS Voice Processing I/O çš„åŸç”Ÿå›éŸ³æ¶ˆé™¤ï¼ˆAECï¼‰
//
//  åŸç†ï¼š
//  - Voice Processing I/O æœƒè‡ªå‹•å¾éº¥å…‹é¢¨è¼¸å…¥ä¸­æ¸›å»è¼¸å‡ºä¿¡è™Ÿï¼ˆTTS æ’­æ”¾ï¼‰
//  - ä½†é€™éœ€è¦éŒ„éŸ³å’Œæ’­æ”¾åœ¨åŒä¸€å€‹ AVAudioEngine ä¸­
//  - é€™æ¨£ AEC æ‰èƒ½ç²å–ã€Œåƒè€ƒä¿¡è™Ÿã€é€²è¡Œå›éŸ³æ¶ˆé™¤
//

import Foundation
import AVFoundation
import Combine

/// çµ±ä¸€éŸ³é »ç®¡ç†å™¨ï¼ˆå›éŸ³æ¶ˆé™¤æ ¸å¿ƒï¼‰
@Observable
final class AudioManager {

    // MARK: - Singleton

    static let shared = AudioManager()

    // MARK: - Properties

    /// éŒ„éŸ³ç‹€æ…‹
    private(set) var recordingState: AudioRecordingState = .idle

    /// TTS æ’­æ”¾ç‹€æ…‹
    private(set) var isPlayingTTS: Bool = false

    /// ç•¶å‰æ’­æ”¾çš„ TTS æ–‡æœ¬ï¼ˆç”¨æ–¼æœå‹™å™¨ç«¯å›éŸ³æª¢æ¸¬å‚™ç”¨ï¼‰
    private(set) var currentTTSText: String?

    /// â­ï¸ æ˜¯å¦æš«åœç™¼é€éŸ³é »ï¼ˆTTS æ’­æ”¾æ™‚æš«åœï¼Œé¿å…å›éŸ³è¢«éŒ„åˆ°ï¼‰
    private(set) var isSendingPaused: Bool = false

    /// â­ï¸ é˜²æ­¢ onTTSPlaybackComplete é‡è¤‡èª¿ç”¨
    private var hasTriggeredCompletion: Bool = false

    /// æ“´éŸ³æ¨¡å¼
    var isSpeakerMode: Bool = true {
        didSet {
            if oldValue != isSpeakerMode {
                updateOutputRoute()
            }
        }
    }

    // MARK: - çµ±ä¸€ AVAudioEngineï¼ˆé—œéµï¼ï¼‰

    /// å–®ä¸€éŸ³é »å¼•æ“ï¼ˆéŒ„éŸ³å’Œæ’­æ”¾å…±ç”¨ï¼‰
    private let audioEngine = AVAudioEngine()

    /// æ’­æ”¾å™¨ç¯€é»ï¼ˆTTS æ’­æ”¾ç”¨ï¼‰
    private var playerNode: AVAudioPlayerNode?

    /// EQ ç¯€é»ï¼ˆéŸ³é‡æ”¾å¤§ç”¨ï¼‰
    private var eqNode: AVAudioUnitEQ?

    /// æ··éŸ³å™¨ç¯€é»
    private var mixerNode: AVAudioMixerNode?

    // MARK: - éŒ„éŸ³ç›¸é—œ

    private var audioConverter: AVAudioConverter?
    private var inputFormat: AVAudioFormat?
    private var outputFormat: AVAudioFormat?

    /// éŸ³é »ç·©è¡å€
    private var audioBufferCollector: [Data] = []
    private var bufferTimer: Timer?
    private let bufferInterval: TimeInterval = 0.25

    /// ç™¼é€è¨ˆæ•¸
    private var sendCount = 0
    private let maxChunkSize = 25600

    // MARK: - TTS æ’­æ”¾ç›¸é—œ

    private var audioFile: AVAudioFile?
    private var playbackTimer: Timer?

    /// éŸ³é‡å¢ç›Šï¼ˆdBï¼‰
    var volumeBoostDB: Float = 6.0

    // MARK: - Combine Publishers

    private let audioDataSubject = PassthroughSubject<Data, Never>()

    var audioDataPublisher: AnyPublisher<Data, Never> {
        audioDataSubject.eraseToAnyPublisher()
    }

    /// TTS æ’­æ”¾å®Œæˆå›èª¿
    var onTTSPlaybackFinished: (() -> Void)?

    // MARK: - Initialization

    private init() {
        setupAudioEngine()
    }

    // MARK: - Audio Engine Setup

    /// è¨­ç½®çµ±ä¸€çš„éŸ³é »å¼•æ“
    private func setupAudioEngine() {
        // å‰µå»ºç¯€é»
        playerNode = AVAudioPlayerNode()
        eqNode = AVAudioUnitEQ(numberOfBands: 1)
        mixerNode = AVAudioMixerNode()

        guard let playerNode = playerNode,
              let eqNode = eqNode,
              let mixerNode = mixerNode else {
            print("âŒ [AudioManager] ç„¡æ³•å‰µå»ºéŸ³é »ç¯€é»")
            return
        }

        // é™„åŠ ç¯€é»åˆ°å¼•æ“
        audioEngine.attach(playerNode)
        audioEngine.attach(eqNode)
        audioEngine.attach(mixerNode)

        print("âœ… [AudioManager] éŸ³é »ç¯€é»å·²é™„åŠ ")
    }

    // MARK: - Audio Session Configuration

    /// é…ç½® Audio Sessionï¼ˆå•Ÿç”¨å›éŸ³æ¶ˆé™¤ï¼‰
    private func configureAudioSession() throws {
        let session = AVAudioSession.sharedInstance()

        // â­ï¸ é—œéµè¨­ç½®ï¼š
        // - .playAndRecord: åŒæ™‚éŒ„éŸ³å’Œæ’­æ”¾
        // - .voiceChat: å•Ÿç”¨ Voice Processing I/Oï¼ˆåŒ…å« AECã€NSã€AGCï¼‰
        // - .allowBluetooth: æ”¯æŒè—ç‰™è¨­å‚™
        try session.setCategory(.playAndRecord, mode: .voiceChat, options: [.allowBluetooth])
        try session.setActive(true)

        print("ğŸ”‡ [AudioManager] Audio Session é…ç½®å®Œæˆ")
        print("   Category: \(session.category.rawValue)")
        print("   Mode: \(session.mode.rawValue) (voiceChat = AEC å•Ÿç”¨)")
        print("   Route: \(session.currentRoute.outputs.first?.portType.rawValue ?? "unknown")")

        // è¨­ç½®æ“´éŸ³æ¨¡å¼
        updateOutputRoute()
    }

    /// æ›´æ–°è¼¸å‡ºè·¯ç”±ï¼ˆæ“´éŸ³/è½ç­’ï¼‰
    private func updateOutputRoute() {
        do {
            let session = AVAudioSession.sharedInstance()
            if isSpeakerMode {
                try session.overrideOutputAudioPort(.speaker)
                print("ğŸ“¢ [AudioManager] æ“´éŸ³æ¨¡å¼ï¼šæšè²å™¨")
            } else {
                try session.overrideOutputAudioPort(.none)
                print("ğŸ“± [AudioManager] è½ç­’æ¨¡å¼")
            }
        } catch {
            print("âŒ [AudioManager] æ›´æ–°è¼¸å‡ºè·¯ç”±å¤±æ•—: \(error)")
        }
    }

    // MARK: - Recording Methods

    /// è«‹æ±‚éº¥å…‹é¢¨æ¬Šé™
    func requestPermission() async -> Bool {
        await withCheckedContinuation { continuation in
            AVAudioApplication.requestRecordPermission { granted in
                continuation.resume(returning: granted)
            }
        }
    }

    /// é–‹å§‹éŒ„éŸ³
    func startRecording() throws {
        guard recordingState != .recording else { return }

        // é…ç½® Audio Session
        try configureAudioSession()

        // ç²å–è¼¸å…¥æ ¼å¼
        let inputNode = audioEngine.inputNode
        inputFormat = inputNode.outputFormat(forBus: 0)

        guard let inputFormat = inputFormat else {
            throw AudioRecordingError.invalidFormat
        }

        // ç›®æ¨™æ ¼å¼ï¼š16kHz mono 16-bit PCM
        var asbd = AudioStreamBasicDescription(
            mSampleRate: 16000,
            mFormatID: kAudioFormatLinearPCM,
            mFormatFlags: kLinearPCMFormatFlagIsSignedInteger | kLinearPCMFormatFlagIsPacked,
            mBytesPerPacket: 2,
            mFramesPerPacket: 1,
            mBytesPerFrame: 2,
            mChannelsPerFrame: 1,
            mBitsPerChannel: 16,
            mReserved: 0
        )
        outputFormat = AVAudioFormat(streamDescription: &asbd)

        guard let outputFormat = outputFormat else {
            throw AudioRecordingError.invalidFormat
        }

        // å‰µå»ºè½‰æ›å™¨
        audioConverter = AVAudioConverter(from: inputFormat, to: outputFormat)

        guard audioConverter != nil else {
            print("âŒ [AudioManager] ç„¡æ³•å‰µå»ºéŸ³é »è½‰æ›å™¨")
            throw AudioRecordingError.invalidFormat
        }

        // â­ï¸ é€£æ¥æ’­æ”¾ç¯€é»åˆ°æ··éŸ³å™¨
        // é€™æ¨£ TTS æ’­æ”¾çš„è²éŸ³æœƒç¶“éåŒä¸€å€‹ Engineï¼ŒAEC å¯ä»¥ç²å–åƒè€ƒä¿¡è™Ÿ
        connectPlaybackNodes()

        // å®‰è£éŒ„éŸ³ Tap
        let bufferSize: AVAudioFrameCount = 4096
        print("ğŸ¤ [AudioManager] å®‰è£éŸ³é » Tap")
        print("   è¼¸å…¥æ ¼å¼: sampleRate=\(inputFormat.sampleRate), channels=\(inputFormat.channelCount)")
        print("   è¼¸å‡ºæ ¼å¼: sampleRate=\(outputFormat.sampleRate), channels=\(outputFormat.channelCount)")

        inputNode.installTap(onBus: 0, bufferSize: bufferSize, format: inputFormat) { [weak self] buffer, _ in
            self?.processAudioBuffer(buffer)
        }

        // å•Ÿå‹•å¼•æ“
        try audioEngine.start()
        print("ğŸ”Š [AudioManager] éŸ³é »å¼•æ“å·²å•Ÿå‹•ï¼ˆçµ±ä¸€ Engineï¼ŒAEC å•Ÿç”¨ï¼‰")

        // å•Ÿå‹•ç·©è¡å€å®šæ™‚å™¨
        startBufferTimer()

        recordingState = .recording
        print("ğŸ™ï¸ [AudioManager] é–‹å§‹éŒ„éŸ³ï¼ˆå…¨é›™å·¥æ¨¡å¼ï¼‰")
    }

    /// é€£æ¥æ’­æ”¾ç¯€é»
    private func connectPlaybackNodes() {
        guard let playerNode = playerNode,
              let eqNode = eqNode else { return }

        // ç²å–è¼¸å‡ºæ ¼å¼ï¼ˆä½¿ç”¨æ¨™æº–æ ¼å¼ï¼‰
        let outputFormat = audioEngine.outputNode.inputFormat(forBus: 0)

        // é€£æ¥ï¼šPlayerNode â†’ EQ â†’ MainMixer â†’ Output
        audioEngine.connect(playerNode, to: eqNode, format: outputFormat)
        audioEngine.connect(eqNode, to: audioEngine.mainMixerNode, format: outputFormat)

        // é…ç½® EQ
        eqNode.globalGain = volumeBoostDB
        let band = eqNode.bands[0]
        band.filterType = .parametric
        band.frequency = 1000
        band.bandwidth = 2.0
        band.gain = volumeBoostDB
        band.bypass = false

        print("ğŸ”Š [AudioManager] æ’­æ”¾ç¯€é»å·²é€£æ¥ï¼ŒéŸ³é‡å¢ç›Š: +\(volumeBoostDB * 2) dB")
    }

    /// åœæ­¢éŒ„éŸ³
    func stopRecording() {
        guard recordingState == .recording else { return }

        // åœæ­¢å®šæ™‚å™¨
        stopBufferTimer()

        // ç™¼é€å‰©é¤˜ç·©è¡å€
        flushBuffer()

        // ç§»é™¤ Tap
        audioEngine.inputNode.removeTap(onBus: 0)

        // åœæ­¢å¼•æ“
        audioEngine.stop()

        // é‡è¨­ Audio Session
        try? resetAudioSession()

        print("â¹ï¸ [AudioManager] åœæ­¢éŒ„éŸ³ (ç¸½è¨ˆç™¼é€ \(sendCount) æ¬¡)")
        sendCount = 0
        recordingState = .idle
    }

    // MARK: - TTS Playback Methods

    /// æ’­æ”¾ TTS éŸ³é »
    /// - Parameters:
    ///   - audioData: MP3 éŸ³é »æ•¸æ“š
    ///   - text: æ­£åœ¨æ’­æ”¾çš„æ–‡æœ¬ï¼ˆç”¨æ–¼å›éŸ³æª¢æ¸¬ï¼‰
    func playTTS(audioData: Data, text: String? = nil) throws {
        // åœæ­¢èˆŠçš„æ’­æ”¾
        stopTTS()

        currentTTSText = text
        isPlayingTTS = true
        hasTriggeredCompletion = false  // é‡ç½®å®Œæˆæ¨™èªŒ

        // â­ï¸ æš«åœç™¼é€éŸ³é »åˆ°æœå‹™å™¨ï¼ˆé¿å…å›éŸ³è¢«éŒ„åˆ°ï¼‰
        isSendingPaused = true
        print("â¸ï¸ [AudioManager] æš«åœç™¼é€éŸ³é »ï¼ˆTTS æ’­æ”¾ä¸­ï¼Œé¿å…å›éŸ³ï¼‰")

        // ç¢ºä¿å¼•æ“æ­£åœ¨é‹è¡Œ
        if !audioEngine.isRunning {
            try audioEngine.start()
        }

        // å¯«å…¥è‡¨æ™‚æ–‡ä»¶
        let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent(UUID().uuidString + ".mp3")
        try audioData.write(to: tempURL)

        // å‰µå»ºéŸ³é »æ–‡ä»¶
        audioFile = try AVAudioFile(forReading: tempURL)

        guard let audioFile = audioFile,
              let playerNode = playerNode else {
            throw TTSError.serverError("ç„¡æ³•å‰µå»ºéŸ³é »æ–‡ä»¶")
        }

        // æª¢æŸ¥æ’­æ”¾ç¯€é»æ˜¯å¦å·²é€£æ¥
        if playerNode.engine == nil {
            connectPlaybackNodes()
        }

        print("â–¶ï¸ [AudioManager] æ’­æ”¾ TTS")
        print("   æ–‡æœ¬: \(text?.prefix(30) ?? "unknown")...")
        print("   é•·åº¦: \(audioFile.length) frames")

        // èª¿åº¦æ–‡ä»¶æ’­æ”¾
        playerNode.scheduleFile(audioFile, at: nil, completionCallbackType: .dataPlayedBack) { [weak self] _ in
            DispatchQueue.main.async {
                self?.onTTSPlaybackComplete()
            }
        }

        // é–‹å§‹æ’­æ”¾
        playerNode.play()

        // ç›£æ§æ’­æ”¾ç‹€æ…‹
        startPlaybackMonitor()
    }

    /// TTS æ’­æ”¾å®Œæˆè™•ç†
    private func onTTSPlaybackComplete() {
        // â­ï¸ é˜²æ­¢é‡è¤‡èª¿ç”¨ï¼ˆscheduleFile å›èª¿å’Œ playbackTimer éƒ½å¯èƒ½è§¸ç™¼ï¼‰
        guard !hasTriggeredCompletion else {
            print("âš ï¸ [AudioManager] å¿½ç•¥é‡è¤‡çš„æ’­æ”¾å®Œæˆå›èª¿")
            return
        }
        hasTriggeredCompletion = true

        print("âœ… [AudioManager] TTS æ’­æ”¾å®Œæˆ")
        isPlayingTTS = false
        currentTTSText = nil

        // â­ï¸ æ¢å¾©ç™¼é€éŸ³é »åˆ°æœå‹™å™¨
        isSendingPaused = false
        print("â–¶ï¸ [AudioManager] æ¢å¾©ç™¼é€éŸ³é »")

        cleanupPlayback()
        onTTSPlaybackFinished?()
    }

    /// åœæ­¢ TTS æ’­æ”¾
    func stopTTS() {
        playbackTimer?.invalidate()
        playbackTimer = nil

        playerNode?.stop()

        if let audioFile = audioFile {
            try? FileManager.default.removeItem(at: audioFile.url)
        }
        audioFile = nil

        isPlayingTTS = false
        currentTTSText = nil

        // â­ï¸ æ¢å¾©ç™¼é€éŸ³é »
        if isSendingPaused {
            isSendingPaused = false
            print("â–¶ï¸ [AudioManager] æ¢å¾©ç™¼é€éŸ³é »ï¼ˆTTS å·²åœæ­¢ï¼‰")
        }
    }

    /// å•Ÿå‹•æ’­æ”¾ç›£æ§
    private func startPlaybackMonitor() {
        playbackTimer?.invalidate()
        playbackTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] timer in
            guard let self = self,
                  let node = self.playerNode else {
                timer.invalidate()
                return
            }

            if !node.isPlaying && self.isPlayingTTS {
                timer.invalidate()
                DispatchQueue.main.async {
                    self.onTTSPlaybackComplete()
                }
            }
        }
    }

    /// æ¸…ç†æ’­æ”¾è³‡æº
    private func cleanupPlayback() {
        playbackTimer?.invalidate()
        playbackTimer = nil

        if let audioFile = audioFile {
            try? FileManager.default.removeItem(at: audioFile.url)
        }
        audioFile = nil
    }

    // MARK: - Audio Buffer Processing

    /// è™•ç†éŸ³é »ç·©è¡å€
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let converter = audioConverter,
              let outputFormat = outputFormat else { return }

        // è¨ˆç®—è¼¸å‡ºç·©è¡å€å¤§å°
        let ratio = outputFormat.sampleRate / buffer.format.sampleRate
        let outputFrameCapacity = AVAudioFrameCount(Double(buffer.frameLength) * ratio) + 1

        guard let outputBuffer = AVAudioPCMBuffer(
            pcmFormat: outputFormat,
            frameCapacity: outputFrameCapacity
        ) else { return }

        // è½‰æ›éŸ³é »
        var hasProvidedData = false
        var error: NSError?
        let status = converter.convert(to: outputBuffer, error: &error) { _, outStatus in
            if hasProvidedData {
                outStatus.pointee = .noDataNow
                return nil
            }
            hasProvidedData = true
            outStatus.pointee = .haveData
            return buffer
        }

        if status == .error || error != nil {
            return
        }

        // æ·»åŠ åˆ°ç·©è¡å€
        if let channelData = outputBuffer.int16ChannelData {
            let frameLength = Int(outputBuffer.frameLength)
            if frameLength > 0 {
                let data = Data(bytes: channelData[0], count: frameLength * 2)
                audioBufferCollector.append(data)
            }
        }
    }

    /// å•Ÿå‹•ç·©è¡å€å®šæ™‚å™¨
    private func startBufferTimer() {
        bufferTimer = Timer.scheduledTimer(withTimeInterval: bufferInterval, repeats: true) { [weak self] _ in
            self?.flushBuffer()
        }
    }

    /// åœæ­¢ç·©è¡å€å®šæ™‚å™¨
    private func stopBufferTimer() {
        bufferTimer?.invalidate()
        bufferTimer = nil
    }

    /// æ¸…ç©ºä¸¦ç™¼é€ç·©è¡å€
    private func flushBuffer() {
        guard !audioBufferCollector.isEmpty else { return }

        // â­ï¸ TTS æ’­æ”¾æ™‚æš«åœç™¼é€ï¼ˆé¿å…å›éŸ³è¢«éŒ„åˆ°ï¼‰
        if isSendingPaused {
            // ä¸Ÿæ£„ç·©è¡å€ï¼ˆTTS æ’­æ”¾ä¸­çš„éŸ³é »å¯èƒ½åŒ…å«å›éŸ³ï¼‰
            audioBufferCollector.removeAll()
            return
        }

        // åˆä½µç·©è¡å€
        var combinedData = Data()
        for buffer in audioBufferCollector {
            combinedData.append(buffer)
        }
        audioBufferCollector.removeAll()

        // åˆ†å‰²ç™¼é€
        var offset = 0
        while offset < combinedData.count {
            let chunkSize = min(maxChunkSize, combinedData.count - offset)
            let chunk = combinedData.subdata(in: offset..<(offset + chunkSize))

            sendCount += 1
            if sendCount == 1 || sendCount % 20 == 0 {
                print("ğŸ“¤ [AudioManager] ç™¼é€éŸ³é » #\(sendCount): \(chunk.count) bytes")
            }
            audioDataSubject.send(chunk)

            offset += chunkSize
        }
    }

    /// é‡è¨­ Audio Session
    private func resetAudioSession() throws {
        let session = AVAudioSession.sharedInstance()
        try session.setActive(false, options: .notifyOthersOnDeactivation)
    }
}
